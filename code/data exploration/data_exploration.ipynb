{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"<location of repo>/aml-mlops-workshop/outputs/raw_data/raw_subset_train.csv\")\n",
    "test = pd.read_csv(\"<location of repo>/aml-mlops-workshop/outputs/raw_data/raw_subset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0                                               text  target\n0           1969  From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...       1\n1            416  From: mike@starburst.umd.edu (Michael F. Santa...       2\n2           1707  From: higgins@fnalf.fnal.gov (Bill Higgins-- B...       2\n3           1285  From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...       3\n4            804  From: nsmca@aurora.alaska.edu Subject: Re: Jem...       2\n...          ...                                                ...     ...\n1012        1920  From: dewey@risc.sps.mot.com (Dewey Henize) Su...       0\n1013        1271  From: C.O.EGALON@LARC.NASA.GOV (CLAUDIO OLIVEI...       2\n1014        1786  From: havardn@edb.tih.no (Haavard Nesse,o92a) ...       1\n1015         632  From: pharvey@quack.kfu.com (Paul Harvey) Subj...       3\n1016        1709  From: eapu207@orion.oac.uci.edu (John Peter Ko...       1\n\n[1017 rows x 3 columns]\n"
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0                                               text  target\n0           464  From: bil@okcforum.osrhe.edu (Bill Conner) Sub...       0\n1           612  From: marshall@csugrad.cs.vt.edu (Kevin Marsha...       0\n2          1077  From: acooper@mac.cc.macalstr.edu (Turin Turam...       0\n3           820  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0\n4           920  From: danb@shell.portal.com (Dan E Babcock) Su...       0\n..          ...                                                ...     ...\n671         775  From: cs89ssg@brunel.ac.uk (Sunil Gupta) Subje...       1\n672         625  From: mathew <mathew@mantis.co.uk> Subject: Re...       0\n673         156  From: jgreen@trumpet.calpoly.edu (James Thomas...       0\n674         596  From: gorgen@ann-arbor.applicon.slb.com (David...       1\n675         868  From: I3150101@dbstu1.rz.tu-bs.de (Benedikt Ro...       0\n\n[676 rows x 3 columns]\n"
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "object\nobject\nint64\nint64\n"
    }
   ],
   "source": [
    "# check the column types\n",
    "print(train.text.dtype)\n",
    "print(test.text.dtype)\n",
    "print(train.target.dtype)\n",
    "print(test.target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0    False\ntext          False\ntarget        False\ndtype: bool\nUnnamed: 0    False\ntext          False\ntarget        False\ndtype: bool\n"
    }
   ],
   "source": [
    "# check if there are non/na values present in the data\n",
    "print(train.isnull().all())\n",
    "print(test.isnull().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate for every sentence in the dataset the language\n",
    "# note that this could take a couple of minutes\n",
    "lang_train =  np.array([])\n",
    "lang_test = np.array([])\n",
    "for i in range(0, len(train)):\n",
    "    lang_train =  np.append(lang_train,detect(train.text.values[i]))\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    lang_test = np.append(lang_test, detect(test.text.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\n"
    }
   ],
   "source": [
    "# check if all sentences are indeed english\n",
    "test2 = lang_train == 'en'\n",
    "test1 = lang_test == 'en'\n",
    "print(test2.all())\n",
    "print(test1.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.25\n0.04287821802571039\n"
    }
   ],
   "source": [
    "# investigare the mean of classes and their standard deviation\n",
    "# this is very usefull to see if we have balanced classes or \n",
    "classes = train.target.value_counts(normalize=True)\n",
    "train_mean = classes.mean()\n",
    "print(train_mean)\n",
    "train_std = classes.std()\n",
    "print(train_std)\n",
    "if train_std > 0.05:\n",
    "    print(\"WARNING: CLasses might be imbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.25\n0.04204932072056773\n"
    }
   ],
   "source": [
    "# do the same for the test data set\n",
    "classes = test.target.value_counts(normalize=True)\n",
    "test_mean = classes.mean()\n",
    "print(test_mean)\n",
    "test_std = classes.std()\n",
    "print(test_std)\n",
    "if train_std > 0.05:\n",
    "    print(\"WARNING: CLasses might be imbalanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data for further investigation\n",
    "import string\n",
    "\n",
    "# make every thing lower case\n",
    "train.text = train.text.apply(lambda x: x.lower())\n",
    "test.text = test.text.apply(lambda x: x.lower())\n",
    "\n",
    "# remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "train.text = train.text.apply(\n",
    "    lambda x: x.translate(translator))\n",
    "test.text = test.text.apply(\n",
    "    lambda x: x.translate(translator))\n",
    "\n",
    "# remoce digits\n",
    "train.text = train.text.apply(\n",
    "    lambda x: x.translate(string.digits))\n",
    "test.text = test.text.apply(\n",
    "    lambda x: x.translate(string.digits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\mideboer.EUROPE\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "clean_text_train = train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "clean_text_test = test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  avg_word\n0  From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...  5.563025\n1  From: mike@starburst.umd.edu (Michael F. Santa...  5.411602\n2  From: higgins@fnalf.fnal.gov (Bill Higgins-- B...  5.710183\n3  From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...  5.866667\n4  From: nsmca@aurora.alaska.edu Subject: Re: Jem...  5.317568",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>avg_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...</td>\n      <td>5.563025</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: mike@starburst.umd.edu (Michael F. Santa...</td>\n      <td>5.411602</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: higgins@fnalf.fnal.gov (Bill Higgins-- B...</td>\n      <td>5.710183</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...</td>\n      <td>5.866667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: nsmca@aurora.alaska.edu Subject: Re: Jem...</td>\n      <td>5.317568</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# calculate the average word length\n",
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['text'].apply(lambda x: avg_word(x))\n",
    "train[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  avg_word\n0  From: bil@okcforum.osrhe.edu (Bill Conner) Sub...  5.047826\n1  From: marshall@csugrad.cs.vt.edu (Kevin Marsha...  4.969086\n2  From: acooper@mac.cc.macalstr.edu (Turin Turam...  5.482517\n3  From: livesey@solntze.wpd.sgi.com (Jon Livesey...  5.173160\n4  From: danb@shell.portal.com (Dan E Babcock) Su...  6.191011",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>avg_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: bil@okcforum.osrhe.edu (Bill Conner) Sub...</td>\n      <td>5.047826</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: marshall@csugrad.cs.vt.edu (Kevin Marsha...</td>\n      <td>4.969086</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: acooper@mac.cc.macalstr.edu (Turin Turam...</td>\n      <td>5.482517</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n      <td>5.173160</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: danb@shell.portal.com (Dan E Babcock) Su...</td>\n      <td>6.191011</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# calcuate the average word length\n",
    "test['avg_word'] = test['text'].apply(lambda x: avg_word(x))\n",
    "test[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.566470149229751\n5.52161248317771\n"
    }
   ],
   "source": [
    "# print the mean average word length\n",
    "print(train['avg_word'].mean())\n",
    "print(test['avg_word'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  stopwords\n0  From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...         36\n1  From: mike@starburst.umd.edu (Michael F. Santa...         75\n2  From: higgins@fnalf.fnal.gov (Bill Higgins-- B...         97\n3  From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...         23\n4  From: nsmca@aurora.alaska.edu Subject: Re: Jem...         44",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: mike@starburst.umd.edu (Michael F. Santa...</td>\n      <td>75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: higgins@fnalf.fnal.gov (Bill Higgins-- B...</td>\n      <td>97</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: nsmca@aurora.alaska.edu Subject: Re: Jem...</td>\n      <td>44</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# calculate the number of stop words\n",
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  stopwords\n0  From: bil@okcforum.osrhe.edu (Bill Conner) Sub...         86\n1  From: marshall@csugrad.cs.vt.edu (Kevin Marsha...        276\n2  From: acooper@mac.cc.macalstr.edu (Turin Turam...        198\n3  From: livesey@solntze.wpd.sgi.com (Jon Livesey...         77\n4  From: danb@shell.portal.com (Dan E Babcock) Su...         20",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: bil@okcforum.osrhe.edu (Bill Conner) Sub...</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: marshall@csugrad.cs.vt.edu (Kevin Marsha...</td>\n      <td>276</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: acooper@mac.cc.macalstr.edu (Turin Turam...</td>\n      <td>198</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n      <td>77</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: danb@shell.portal.com (Dan E Babcock) Su...</td>\n      <td>20</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# calculate the number of stop words\n",
    "test['stopwords'] = test['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "test[['text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "96.90855457227138\n111.84319526627219\n"
    }
   ],
   "source": [
    "# calculate the average number of stop words\n",
    "print(train['stopwords'].mean())\n",
    "print(test['stopwords'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  sentiment\n0  From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...   0.097803\n1  From: mike@starburst.umd.edu (Michael F. Santa...   0.073117\n2  From: higgins@fnalf.fnal.gov (Bill Higgins-- B...   0.158598\n3  From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...  -0.113333\n4  From: nsmca@aurora.alaska.edu Subject: Re: Jem...   0.080385",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: IMAGING.CLUB@OFFICE.WANG.COM (\"Imaging C...</td>\n      <td>0.097803</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: mike@starburst.umd.edu (Michael F. Santa...</td>\n      <td>0.073117</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: higgins@fnalf.fnal.gov (Bill Higgins-- B...</td>\n      <td>0.158598</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: rosst@pogo.wv.tek.com (Ross Taylor) Subj...</td>\n      <td>-0.113333</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: nsmca@aurora.alaska.edu Subject: Re: Jem...</td>\n      <td>0.080385</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# calculate the sentiment of a text message\n",
    "from textblob import TextBlob\n",
    "train['sentiment'] = train['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  sentiment\n0  From: bil@okcforum.osrhe.edu (Bill Conner) Sub...   0.031373\n1  From: marshall@csugrad.cs.vt.edu (Kevin Marsha...  -0.111508\n2  From: acooper@mac.cc.macalstr.edu (Turin Turam...   0.075206\n3  From: livesey@solntze.wpd.sgi.com (Jon Livesey...  -0.297672\n4  From: danb@shell.portal.com (Dan E Babcock) Su...   0.139881",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>From: bil@okcforum.osrhe.edu (Bill Conner) Sub...</td>\n      <td>0.031373</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>From: marshall@csugrad.cs.vt.edu (Kevin Marsha...</td>\n      <td>-0.111508</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>From: acooper@mac.cc.macalstr.edu (Turin Turam...</td>\n      <td>0.075206</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n      <td>-0.297672</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>From: danb@shell.portal.com (Dan E Babcock) Su...</td>\n      <td>0.139881</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "# calculate the sentiment of a text message\n",
    "from textblob import TextBlob\n",
    "test['sentiment'] = test['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "test[['text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.06749869848993294\n0.08094657902434026\n"
    }
   ],
   "source": [
    "# print the average sentiment of the data set\n",
    "print(train['sentiment'].mean())\n",
    "print(test['sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcutate tfidf for every catergory in the data\n",
    "from collections import Counter\n",
    "df2= pd.DataFrame()\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for classes in range(0,4):\n",
    "    vocab = Counter()\n",
    "    df_train = clean_text_train[train.target == classes]\n",
    "    for text in df_train:\n",
    "        for word in text.split(' '):\n",
    "            vocab[word.lower()] += 1\n",
    "\n",
    "    word1 = 'word' + str(classes)\n",
    "    count = 'count' + str(classes)\n",
    "    idf = 'idf' + str(classes)\n",
    "    tfidf = 'tfidf' + str(classes)\n",
    "\n",
    "    df = pd.DataFrame(list(vocab.items()), columns=[word1, count])\n",
    "\n",
    "    for i,word in enumerate(df[word1]):\n",
    "        df.loc[i, idf ] = np.log(df_train.shape[0]/(len(df_train[df_train.str.contains(word)]))) \n",
    "\n",
    "    array = df[count] * df[idf]\n",
    "    df[tfidf] = array\n",
    "\n",
    "    df1 = df.sort_values(tfidf, ascending=False, ignore_index=True)\n",
    "    df2[word1] = df1[word1]\n",
    "    df2[count] = df1[count]\n",
    "    df2[idf]  =df1[idf]\n",
    "    df2[tfidf] = df1[tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        word0  count0      idf0      tfidf0       word1  count1      idf1  \\\n0         god     384  0.950482  364.985125        jpeg     220  3.278859   \n1       jesus     146  2.104975  307.326327       image     352  1.599216   \n2      people     294  0.918394  270.007772      images     160  2.275556   \n3      system     132  1.916923  253.033785       files     156  1.939084   \n4     matthew      67  3.526361  236.266155         gif     106  2.344549   \n5     atheism     135  1.711071  230.994525    software     137  1.784934   \n6       bible     121  1.888752  228.538960        data     110  2.180246   \n7    argument     129  1.758699  226.872120        file     171  1.400088   \n8    atheists     204  1.090244  222.409784        also     140  1.706462   \n9       would     256  0.808832  207.060884     version     135  1.725510   \n10    fallacy      57  3.526361  201.002550   available     110  2.013192   \n11       true     109  1.808709  197.149284    graphics     234  0.940555   \n12       must     157  1.252763  196.683786      points      87  2.457878   \n13       many     164  1.141537  187.212123  processing      69  2.968704   \n14    islamic     102  1.834685  187.137820     display      90  2.242767   \n15   morality      96  1.916923  184.024571     package      96  2.093235   \n16    believe     145  1.252763  181.650630       color     106  1.764731   \n17       dont     233  0.771790  179.827142      system      89  2.093235   \n18  religious     102  1.711071  174.529197          3d     117  1.582409   \n19   religion     115  1.501979  172.727557        send      75  2.457878   \n\n        tfidf1       word2  count2      idf2      tfidf2       word3  count3  \\\n0   721.348876      launch     206  1.599039  329.402076       judas      75   \n1   562.924158       space     554  0.500427  277.236512       jesus     194   \n2   364.089027        data     129  1.995921  257.473753         god     207   \n3   302.497133       would     265  0.863692  228.878293      people     217   \n4   248.522225   satellite      94  2.327278  218.764104   objective      76   \n5   244.535890  commercial      71  2.769110  196.606843       would     236   \n6   239.827086     shuttle     100  1.788281  178.828120        tyre      51   \n7   239.414994     program     102  1.689190  172.297411       greek      54   \n8   238.904664        moon     107  1.565138  167.469729       bible     105   \n9   232.943861        dont     118  1.396802  164.822676    morality      90   \n10  221.451137        also     124  1.328749  164.764861        good     108   \n11  220.089953  spacecraft      81  1.995921  161.669566         law      84   \n12  213.835384       first     110  1.454790  160.026856  christians      83   \n13  204.840548       orbit     118  1.355417  159.939220        life      85   \n14  201.848994       lunar      70  2.258285  158.079938        said      97   \n15  200.950547  satellites      50  3.094533  154.726643     matthew      57   \n16  187.061464      market      50  2.951432  147.571601      values      48   \n17  186.297903      system      85  1.689190  143.581176     hanging      31   \n18  185.141881     mission      69  2.075963  143.241466        many      94   \n19  184.340848        said      70  2.021896  141.532724        also      98   \n\n        idf3      tfidf3  \n0   3.912023  293.401725  \n1   1.406497  272.860431  \n2   0.941609  194.912968  \n3   0.879477  190.846457  \n4   2.353878  178.894757  \n5   0.744440  175.687952  \n6   3.352407  170.972768  \n7   3.101093  167.459011  \n8   1.584745  166.398256  \n9   1.832581  164.932332  \n10  1.427116  154.128566  \n11  1.832581  153.936843  \n12  1.714798  142.328270  \n13  1.634756  138.954236  \n14  1.427116  138.430286  \n15  2.407946  137.252900  \n16  2.733368  131.201664  \n17  4.199705  130.190857  \n18  1.347074  126.624923  \n19  1.290984  126.516450  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word0</th>\n      <th>count0</th>\n      <th>idf0</th>\n      <th>tfidf0</th>\n      <th>word1</th>\n      <th>count1</th>\n      <th>idf1</th>\n      <th>tfidf1</th>\n      <th>word2</th>\n      <th>count2</th>\n      <th>idf2</th>\n      <th>tfidf2</th>\n      <th>word3</th>\n      <th>count3</th>\n      <th>idf3</th>\n      <th>tfidf3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>god</td>\n      <td>384</td>\n      <td>0.950482</td>\n      <td>364.985125</td>\n      <td>jpeg</td>\n      <td>220</td>\n      <td>3.278859</td>\n      <td>721.348876</td>\n      <td>launch</td>\n      <td>206</td>\n      <td>1.599039</td>\n      <td>329.402076</td>\n      <td>judas</td>\n      <td>75</td>\n      <td>3.912023</td>\n      <td>293.401725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>jesus</td>\n      <td>146</td>\n      <td>2.104975</td>\n      <td>307.326327</td>\n      <td>image</td>\n      <td>352</td>\n      <td>1.599216</td>\n      <td>562.924158</td>\n      <td>space</td>\n      <td>554</td>\n      <td>0.500427</td>\n      <td>277.236512</td>\n      <td>jesus</td>\n      <td>194</td>\n      <td>1.406497</td>\n      <td>272.860431</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>people</td>\n      <td>294</td>\n      <td>0.918394</td>\n      <td>270.007772</td>\n      <td>images</td>\n      <td>160</td>\n      <td>2.275556</td>\n      <td>364.089027</td>\n      <td>data</td>\n      <td>129</td>\n      <td>1.995921</td>\n      <td>257.473753</td>\n      <td>god</td>\n      <td>207</td>\n      <td>0.941609</td>\n      <td>194.912968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>system</td>\n      <td>132</td>\n      <td>1.916923</td>\n      <td>253.033785</td>\n      <td>files</td>\n      <td>156</td>\n      <td>1.939084</td>\n      <td>302.497133</td>\n      <td>would</td>\n      <td>265</td>\n      <td>0.863692</td>\n      <td>228.878293</td>\n      <td>people</td>\n      <td>217</td>\n      <td>0.879477</td>\n      <td>190.846457</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>matthew</td>\n      <td>67</td>\n      <td>3.526361</td>\n      <td>236.266155</td>\n      <td>gif</td>\n      <td>106</td>\n      <td>2.344549</td>\n      <td>248.522225</td>\n      <td>satellite</td>\n      <td>94</td>\n      <td>2.327278</td>\n      <td>218.764104</td>\n      <td>objective</td>\n      <td>76</td>\n      <td>2.353878</td>\n      <td>178.894757</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>atheism</td>\n      <td>135</td>\n      <td>1.711071</td>\n      <td>230.994525</td>\n      <td>software</td>\n      <td>137</td>\n      <td>1.784934</td>\n      <td>244.535890</td>\n      <td>commercial</td>\n      <td>71</td>\n      <td>2.769110</td>\n      <td>196.606843</td>\n      <td>would</td>\n      <td>236</td>\n      <td>0.744440</td>\n      <td>175.687952</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bible</td>\n      <td>121</td>\n      <td>1.888752</td>\n      <td>228.538960</td>\n      <td>data</td>\n      <td>110</td>\n      <td>2.180246</td>\n      <td>239.827086</td>\n      <td>shuttle</td>\n      <td>100</td>\n      <td>1.788281</td>\n      <td>178.828120</td>\n      <td>tyre</td>\n      <td>51</td>\n      <td>3.352407</td>\n      <td>170.972768</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>argument</td>\n      <td>129</td>\n      <td>1.758699</td>\n      <td>226.872120</td>\n      <td>file</td>\n      <td>171</td>\n      <td>1.400088</td>\n      <td>239.414994</td>\n      <td>program</td>\n      <td>102</td>\n      <td>1.689190</td>\n      <td>172.297411</td>\n      <td>greek</td>\n      <td>54</td>\n      <td>3.101093</td>\n      <td>167.459011</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>atheists</td>\n      <td>204</td>\n      <td>1.090244</td>\n      <td>222.409784</td>\n      <td>also</td>\n      <td>140</td>\n      <td>1.706462</td>\n      <td>238.904664</td>\n      <td>moon</td>\n      <td>107</td>\n      <td>1.565138</td>\n      <td>167.469729</td>\n      <td>bible</td>\n      <td>105</td>\n      <td>1.584745</td>\n      <td>166.398256</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>would</td>\n      <td>256</td>\n      <td>0.808832</td>\n      <td>207.060884</td>\n      <td>version</td>\n      <td>135</td>\n      <td>1.725510</td>\n      <td>232.943861</td>\n      <td>dont</td>\n      <td>118</td>\n      <td>1.396802</td>\n      <td>164.822676</td>\n      <td>morality</td>\n      <td>90</td>\n      <td>1.832581</td>\n      <td>164.932332</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>fallacy</td>\n      <td>57</td>\n      <td>3.526361</td>\n      <td>201.002550</td>\n      <td>available</td>\n      <td>110</td>\n      <td>2.013192</td>\n      <td>221.451137</td>\n      <td>also</td>\n      <td>124</td>\n      <td>1.328749</td>\n      <td>164.764861</td>\n      <td>good</td>\n      <td>108</td>\n      <td>1.427116</td>\n      <td>154.128566</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>true</td>\n      <td>109</td>\n      <td>1.808709</td>\n      <td>197.149284</td>\n      <td>graphics</td>\n      <td>234</td>\n      <td>0.940555</td>\n      <td>220.089953</td>\n      <td>spacecraft</td>\n      <td>81</td>\n      <td>1.995921</td>\n      <td>161.669566</td>\n      <td>law</td>\n      <td>84</td>\n      <td>1.832581</td>\n      <td>153.936843</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>must</td>\n      <td>157</td>\n      <td>1.252763</td>\n      <td>196.683786</td>\n      <td>points</td>\n      <td>87</td>\n      <td>2.457878</td>\n      <td>213.835384</td>\n      <td>first</td>\n      <td>110</td>\n      <td>1.454790</td>\n      <td>160.026856</td>\n      <td>christians</td>\n      <td>83</td>\n      <td>1.714798</td>\n      <td>142.328270</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>many</td>\n      <td>164</td>\n      <td>1.141537</td>\n      <td>187.212123</td>\n      <td>processing</td>\n      <td>69</td>\n      <td>2.968704</td>\n      <td>204.840548</td>\n      <td>orbit</td>\n      <td>118</td>\n      <td>1.355417</td>\n      <td>159.939220</td>\n      <td>life</td>\n      <td>85</td>\n      <td>1.634756</td>\n      <td>138.954236</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>islamic</td>\n      <td>102</td>\n      <td>1.834685</td>\n      <td>187.137820</td>\n      <td>display</td>\n      <td>90</td>\n      <td>2.242767</td>\n      <td>201.848994</td>\n      <td>lunar</td>\n      <td>70</td>\n      <td>2.258285</td>\n      <td>158.079938</td>\n      <td>said</td>\n      <td>97</td>\n      <td>1.427116</td>\n      <td>138.430286</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>morality</td>\n      <td>96</td>\n      <td>1.916923</td>\n      <td>184.024571</td>\n      <td>package</td>\n      <td>96</td>\n      <td>2.093235</td>\n      <td>200.950547</td>\n      <td>satellites</td>\n      <td>50</td>\n      <td>3.094533</td>\n      <td>154.726643</td>\n      <td>matthew</td>\n      <td>57</td>\n      <td>2.407946</td>\n      <td>137.252900</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>believe</td>\n      <td>145</td>\n      <td>1.252763</td>\n      <td>181.650630</td>\n      <td>color</td>\n      <td>106</td>\n      <td>1.764731</td>\n      <td>187.061464</td>\n      <td>market</td>\n      <td>50</td>\n      <td>2.951432</td>\n      <td>147.571601</td>\n      <td>values</td>\n      <td>48</td>\n      <td>2.733368</td>\n      <td>131.201664</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dont</td>\n      <td>233</td>\n      <td>0.771790</td>\n      <td>179.827142</td>\n      <td>system</td>\n      <td>89</td>\n      <td>2.093235</td>\n      <td>186.297903</td>\n      <td>system</td>\n      <td>85</td>\n      <td>1.689190</td>\n      <td>143.581176</td>\n      <td>hanging</td>\n      <td>31</td>\n      <td>4.199705</td>\n      <td>130.190857</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>religious</td>\n      <td>102</td>\n      <td>1.711071</td>\n      <td>174.529197</td>\n      <td>3d</td>\n      <td>117</td>\n      <td>1.582409</td>\n      <td>185.141881</td>\n      <td>mission</td>\n      <td>69</td>\n      <td>2.075963</td>\n      <td>143.241466</td>\n      <td>many</td>\n      <td>94</td>\n      <td>1.347074</td>\n      <td>126.624923</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>religion</td>\n      <td>115</td>\n      <td>1.501979</td>\n      <td>172.727557</td>\n      <td>send</td>\n      <td>75</td>\n      <td>2.457878</td>\n      <td>184.340848</td>\n      <td>said</td>\n      <td>70</td>\n      <td>2.021896</td>\n      <td>141.532724</td>\n      <td>also</td>\n      <td>98</td>\n      <td>1.290984</td>\n      <td>126.516450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "# print tfidf for every caterogy in the data.\n",
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitvenvamlcondaa2885660b66d41daa25a25cbab9819c5",
   "display_name": "Python 3.6.10 64-bit ('venvaml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}