{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"C:/Users/mideboer.EUROPE/Documents/GitHub/aml-mlops-workshop/outputs/raw_data/raw_subset_train.csv\")\n",
    "test = pd.read_csv(\"C:/Users/mideboer.EUROPE/Documents/GitHub/aml-mlops-workshop/outputs/raw_data/raw_subset_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0                                               text  target\n0            494  From: clldomps@cs.ruu.nl (Louis van Dompselaar...       1\n1            276  From: bcash@crchh410.NoSubdomain.NoDomain (Bri...       3\n2           1786  From: havardn@edb.tih.no (Haavard Nesse,o92a) ...       1\n3            836  From: et@teal.csn.org (Eric H. Taylor) Subject...       2\n4            781  From: kevin@rotag.mi.org (Kevin Darcy) Subject...       3\n...          ...                                                ...     ...\n1012         982  From: millernw@craft.camp.clarkson.edu (Neal M...       1\n1013        1403  From: ad354@Freenet.carleton.ca (James Owens) ...       3\n1014         961  From: sp1marse@lina (Marco Seirio) Subject: Su...       1\n1015        1084  From: caldwell@facman.ohsu.edu (Larry Caldwell...       3\n1016        1182  From: keith@cco.caltech.edu (Keith Allan Schne...       0\n\n[1017 rows x 3 columns]\n"
    }
   ],
   "source": [
    "print(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0                                               text  target\n0          1263  From: lazio@astrosun.tn.cornell.edu (T. Joseph...       2\n1            84  From: kmr4@po.CWRU.edu (Keith M. Ryan) Subject...       0\n2           289  From: len@schur.math.nwu.edu (Len Evens) Subje...       2\n3           371  From: wats@scicom.AlphaCDC.COM (Bruce Watson) ...       2\n4          1272  From: thomsonal@cpva.saic.com Subject: Drag-fr...       2\n..          ...                                                ...     ...\n671        1329  From:  (Rashid) Subject: Re: Yet more Rushdie ...       0\n672          24  From: daveb@pogo.wv.tek.com (Dave Butler) Subj...       3\n673        1325  From: livesey@solntze.wpd.sgi.com (Jon Livesey...       0\n674         444  From: hexham@acs.ucalgary.ca (Irving Hexham) S...       3\n675         737  From: isaackuo@skippy.berkeley.edu (Isaac Kuo)...       3\n\n[676 rows x 3 columns]\n"
    }
   ],
   "source": [
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "object\nobject\nint64\nint64\n"
    }
   ],
   "source": [
    "print(train.text.dtype)\n",
    "print(test.text.dtype)\n",
    "print(train.target.dtype)\n",
    "print(test.target.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "False"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "train.target.dtype == object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Unnamed: 0    False\ntext          False\ntarget        False\ndtype: bool\nUnnamed: 0    False\ntext          False\ntarget        False\ndtype: bool\n"
    }
   ],
   "source": [
    "print(train.isnull().all())\n",
    "print(test.isnull().all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_train =  np.array([])\n",
    "lang_test = np.array([])\n",
    "for i in range(0, len(train)):\n",
    "    lang_train =  np.append(lang_train,detect(train.text.values[i]))\n",
    "\n",
    "for i in range(0, len(test)):\n",
    "    lang_test = np.append(lang_test, detect(test.text.values[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nTrue\n"
    }
   ],
   "source": [
    "test2 = lang_train == 'en'\n",
    "test1 = lang_test == 'en'\n",
    "print(test2.all())\n",
    "print(test1.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.25\n0.04287821802571039\n"
    }
   ],
   "source": [
    "classes = train.target.value_counts(normalize=True)\n",
    "train_mean = classes.mean()\n",
    "print(train_mean)\n",
    "train_std = classes.std()\n",
    "print(train_std)\n",
    "if train_std > 0.05:\n",
    "    print(\"WARNING: CLasses might be imbalanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.25\n0.04204932072056773\n"
    }
   ],
   "source": [
    "classes = test.target.value_counts(normalize=True)\n",
    "test_mean = classes.mean()\n",
    "print(test_mean)\n",
    "test_std = classes.std()\n",
    "print(test_std)\n",
    "if train_std > 0.05:\n",
    "    print(\"WARNING: CLasses might be imbalanced\")\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if text always start with \"from\"\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# make every thing lower case\n",
    "train.text = train.text.apply(lambda x: x.lower())\n",
    "test.text = test.text.apply(lambda x: x.lower())\n",
    "\n",
    "# remove punctuation\n",
    "translator = str.maketrans('', '', string.punctuation)\n",
    "train.text = train.text.apply(\n",
    "    lambda x: x.translate(translator))\n",
    "test.text = test.text.apply(\n",
    "    lambda x: x.translate(translator))\n",
    "\n",
    "# remoce digits\n",
    "train.text = train.text.apply(\n",
    "    lambda x: x.translate(string.digits))\n",
    "test.text = test.text.apply(\n",
    "    lambda x: x.translate(string.digits))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\mideboer.EUROPE\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "clean_text_train = train['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "clean_text_test = test['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "word  count\n4             subject   1857\n13              lines   1795\n7        organization   1692\n76              would   1576\n21                one   1559\n19             writes   1362\n43            article   1116\n84               dont   1027\n506               god    969\n1044           people    947\n133              like    908\n227              know    872\n162             space    846\n23              image    817\n9          university    804\n574              also    785\n85              think    780\n66    nntppostinghost    745\n229               see    666\n655               get    628\n794              many    627\n457               may    622\n851                us    621\n45                say    617\n117             could    608\n873            system    597\n257              time    587\n348              even    580\n709              well    568\n1034              use    565\n887              good    562\n48                 im    550\n230               way    537\n697              much    509\n1783            jesus    507\n408               new    494\n169             world    484\n969              data    481\n1214          believe    464\n312             first    463\n1004                9    463\n1128             make    450\n3389             jpeg    446\n220         something    443\n1573            point    438\n217              said    434\n434           program    430\n1349         graphics    424\n441                 1    420\n1695              two    417\n"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "vocab = Counter()\n",
    "\n",
    "for text in clean_text_train:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()] += 1\n",
    "\n",
    "for text in clean_text_test:\n",
    "    for word in text.split(' '):\n",
    "        vocab[word.lower()] += 1\n",
    "\n",
    "\n",
    "df = pd.DataFrame(list(vocab.items()), columns=['word', 'count'])\n",
    "df1 = df.sort_values('count', ascending=False)\n",
    "print(df1.head(50))\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                                text  avg_word\n0  from lazioastrosuntncornelledu t joseph lazio ...  5.168490\n1  from kmr4pocwruedu keith m ryan subject re 27 ...  4.815951\n2  from lenschurmathnwuedu len evens subject re s...  4.930556\n3  from watsscicomalphacdccom bruce watson subjec...  5.657534\n4  from thomsonalcpvasaiccom subject dragfree sat...  4.900794",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>avg_word</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>from lazioastrosuntncornelledu t joseph lazio ...</td>\n      <td>5.168490</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>from kmr4pocwruedu keith m ryan subject re 27 ...</td>\n      <td>4.815951</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>from lenschurmathnwuedu len evens subject re s...</td>\n      <td>4.930556</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>from watsscicomalphacdccom bruce watson subjec...</td>\n      <td>5.657534</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>from thomsonalcpvasaiccom subject dragfree sat...</td>\n      <td>4.900794</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 141
    }
   ],
   "source": [
    "def avg_word(sentence):\n",
    "  words = sentence.split()\n",
    "  return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "train['avg_word'] = train['text'].apply(lambda x: avg_word(x))\n",
    "train[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['avg_word'] = test['text'].apply(lambda x: avg_word(x))\n",
    "test[['text','avg_word']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.163787187913941\n5.177996244395777\n"
    }
   ],
   "source": [
    "print(train['avg_word'].mean())\n",
    "print(test['avg_word'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stopwords'] = train['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "train[['text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['stopwords'] = test['text'].apply(lambda x: len([x for x in x.split() if x in stop]))\n",
    "test[['text','stopwords']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['stopwords'].mean())\n",
    "print(test['stopwords'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "train['sentiment'] = train['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "train[['text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "test['sentiment'] = test['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "test[['text','sentiment']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['sentiment'].mean())\n",
    "print(test['sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "df2= pd.DataFrame()\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for classes in range(0,4):\n",
    "    vocab = Counter()\n",
    "    df_train = clean_text_train[train.target == classes]\n",
    "    for text in df_train:\n",
    "        for word in text.split(' '):\n",
    "            vocab[word.lower()] += 1\n",
    "\n",
    "    word1 = 'word' + str(classes)\n",
    "    count = 'count' + str(classes)\n",
    "    idf = 'idf' + str(classes)\n",
    "    tfidf = 'tfidf' + str(classes)\n",
    "\n",
    "    df = pd.DataFrame(list(vocab.items()), columns=[word1, count])\n",
    "\n",
    "    for i,word in enumerate(df[word1]):\n",
    "        df.loc[i, idf ] = np.log(df_train.shape[0]/(len(df_train[df_train.str.contains(word)]))) \n",
    "\n",
    "    array = df[count] * df[idf]\n",
    "    df[tfidf] = array\n",
    "\n",
    "    df1 = df.sort_values(tfidf, ascending=False, ignore_index=True)\n",
    "    df2[word1] = df1[word1]\n",
    "    df2[count] = df1[count]\n",
    "    df2[idf]  =df1[idf]\n",
    "    df2[tfidf] = df1[tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "        word0  count0      idf0      tfidf0       word1  count1      idf1  \\\n0         god     384  0.950482  364.985125        jpeg     220  3.278859   \n1       jesus     146  2.104975  307.326327       image     352  1.599216   \n2      people     294  0.918394  270.007772      images     160  2.275556   \n3      system     132  1.916923  253.033785       files     156  1.939084   \n4     matthew      67  3.526361  236.266155         gif     106  2.344549   \n5     atheism     135  1.711071  230.994525    software     137  1.784934   \n6       bible     121  1.888752  228.538960        data     110  2.180246   \n7    argument     129  1.758699  226.872120        file     171  1.400088   \n8    atheists     204  1.090244  222.409784        also     140  1.706462   \n9       would     256  0.808832  207.060884     version     135  1.725510   \n10    fallacy      57  3.526361  201.002550   available     110  2.013192   \n11       true     109  1.808709  197.149284    graphics     234  0.940555   \n12       must     157  1.252763  196.683786      points      87  2.457878   \n13       many     164  1.141537  187.212123  processing      69  2.968704   \n14    islamic     102  1.834685  187.137820     display      90  2.242767   \n15   morality      96  1.916923  184.024571     package      96  2.093235   \n16    believe     145  1.252763  181.650630       color     106  1.764731   \n17       dont     233  0.771790  179.827142      system      89  2.093235   \n18  religious     102  1.711071  174.529197          3d     117  1.582409   \n19   religion     115  1.501979  172.727557        send      75  2.457878   \n\n        tfidf1       word2  count2      idf2      tfidf2       word3  count3  \\\n0   721.348876      launch     206  1.599039  329.402076       judas      75   \n1   562.924158       space     554  0.500427  277.236512       jesus     194   \n2   364.089027        data     129  1.995921  257.473753         god     207   \n3   302.497133       would     265  0.863692  228.878293      people     217   \n4   248.522225   satellite      94  2.327278  218.764104   objective      76   \n5   244.535890  commercial      71  2.769110  196.606843       would     236   \n6   239.827086     shuttle     100  1.788281  178.828120        tyre      51   \n7   239.414994     program     102  1.689190  172.297411       greek      54   \n8   238.904664        moon     107  1.565138  167.469729       bible     105   \n9   232.943861        dont     118  1.396802  164.822676    morality      90   \n10  221.451137        also     124  1.328749  164.764861        good     108   \n11  220.089953  spacecraft      81  1.995921  161.669566         law      84   \n12  213.835384       first     110  1.454790  160.026856  christians      83   \n13  204.840548       orbit     118  1.355417  159.939220        life      85   \n14  201.848994       lunar      70  2.258285  158.079938        said      97   \n15  200.950547  satellites      50  3.094533  154.726643     matthew      57   \n16  187.061464      market      50  2.951432  147.571601      values      48   \n17  186.297903      system      85  1.689190  143.581176     hanging      31   \n18  185.141881     mission      69  2.075963  143.241466        many      94   \n19  184.340848        said      70  2.021896  141.532724        also      98   \n\n        idf3      tfidf3  \n0   3.912023  293.401725  \n1   1.406497  272.860431  \n2   0.941609  194.912968  \n3   0.879477  190.846457  \n4   2.353878  178.894757  \n5   0.744440  175.687952  \n6   3.352407  170.972768  \n7   3.101093  167.459011  \n8   1.584745  166.398256  \n9   1.832581  164.932332  \n10  1.427116  154.128566  \n11  1.832581  153.936843  \n12  1.714798  142.328270  \n13  1.634756  138.954236  \n14  1.427116  138.430286  \n15  2.407946  137.252900  \n16  2.733368  131.201664  \n17  4.199705  130.190857  \n18  1.347074  126.624923  \n19  1.290984  126.516450  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>word0</th>\n      <th>count0</th>\n      <th>idf0</th>\n      <th>tfidf0</th>\n      <th>word1</th>\n      <th>count1</th>\n      <th>idf1</th>\n      <th>tfidf1</th>\n      <th>word2</th>\n      <th>count2</th>\n      <th>idf2</th>\n      <th>tfidf2</th>\n      <th>word3</th>\n      <th>count3</th>\n      <th>idf3</th>\n      <th>tfidf3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>god</td>\n      <td>384</td>\n      <td>0.950482</td>\n      <td>364.985125</td>\n      <td>jpeg</td>\n      <td>220</td>\n      <td>3.278859</td>\n      <td>721.348876</td>\n      <td>launch</td>\n      <td>206</td>\n      <td>1.599039</td>\n      <td>329.402076</td>\n      <td>judas</td>\n      <td>75</td>\n      <td>3.912023</td>\n      <td>293.401725</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>jesus</td>\n      <td>146</td>\n      <td>2.104975</td>\n      <td>307.326327</td>\n      <td>image</td>\n      <td>352</td>\n      <td>1.599216</td>\n      <td>562.924158</td>\n      <td>space</td>\n      <td>554</td>\n      <td>0.500427</td>\n      <td>277.236512</td>\n      <td>jesus</td>\n      <td>194</td>\n      <td>1.406497</td>\n      <td>272.860431</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>people</td>\n      <td>294</td>\n      <td>0.918394</td>\n      <td>270.007772</td>\n      <td>images</td>\n      <td>160</td>\n      <td>2.275556</td>\n      <td>364.089027</td>\n      <td>data</td>\n      <td>129</td>\n      <td>1.995921</td>\n      <td>257.473753</td>\n      <td>god</td>\n      <td>207</td>\n      <td>0.941609</td>\n      <td>194.912968</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>system</td>\n      <td>132</td>\n      <td>1.916923</td>\n      <td>253.033785</td>\n      <td>files</td>\n      <td>156</td>\n      <td>1.939084</td>\n      <td>302.497133</td>\n      <td>would</td>\n      <td>265</td>\n      <td>0.863692</td>\n      <td>228.878293</td>\n      <td>people</td>\n      <td>217</td>\n      <td>0.879477</td>\n      <td>190.846457</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>matthew</td>\n      <td>67</td>\n      <td>3.526361</td>\n      <td>236.266155</td>\n      <td>gif</td>\n      <td>106</td>\n      <td>2.344549</td>\n      <td>248.522225</td>\n      <td>satellite</td>\n      <td>94</td>\n      <td>2.327278</td>\n      <td>218.764104</td>\n      <td>objective</td>\n      <td>76</td>\n      <td>2.353878</td>\n      <td>178.894757</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>atheism</td>\n      <td>135</td>\n      <td>1.711071</td>\n      <td>230.994525</td>\n      <td>software</td>\n      <td>137</td>\n      <td>1.784934</td>\n      <td>244.535890</td>\n      <td>commercial</td>\n      <td>71</td>\n      <td>2.769110</td>\n      <td>196.606843</td>\n      <td>would</td>\n      <td>236</td>\n      <td>0.744440</td>\n      <td>175.687952</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>bible</td>\n      <td>121</td>\n      <td>1.888752</td>\n      <td>228.538960</td>\n      <td>data</td>\n      <td>110</td>\n      <td>2.180246</td>\n      <td>239.827086</td>\n      <td>shuttle</td>\n      <td>100</td>\n      <td>1.788281</td>\n      <td>178.828120</td>\n      <td>tyre</td>\n      <td>51</td>\n      <td>3.352407</td>\n      <td>170.972768</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>argument</td>\n      <td>129</td>\n      <td>1.758699</td>\n      <td>226.872120</td>\n      <td>file</td>\n      <td>171</td>\n      <td>1.400088</td>\n      <td>239.414994</td>\n      <td>program</td>\n      <td>102</td>\n      <td>1.689190</td>\n      <td>172.297411</td>\n      <td>greek</td>\n      <td>54</td>\n      <td>3.101093</td>\n      <td>167.459011</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>atheists</td>\n      <td>204</td>\n      <td>1.090244</td>\n      <td>222.409784</td>\n      <td>also</td>\n      <td>140</td>\n      <td>1.706462</td>\n      <td>238.904664</td>\n      <td>moon</td>\n      <td>107</td>\n      <td>1.565138</td>\n      <td>167.469729</td>\n      <td>bible</td>\n      <td>105</td>\n      <td>1.584745</td>\n      <td>166.398256</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>would</td>\n      <td>256</td>\n      <td>0.808832</td>\n      <td>207.060884</td>\n      <td>version</td>\n      <td>135</td>\n      <td>1.725510</td>\n      <td>232.943861</td>\n      <td>dont</td>\n      <td>118</td>\n      <td>1.396802</td>\n      <td>164.822676</td>\n      <td>morality</td>\n      <td>90</td>\n      <td>1.832581</td>\n      <td>164.932332</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>fallacy</td>\n      <td>57</td>\n      <td>3.526361</td>\n      <td>201.002550</td>\n      <td>available</td>\n      <td>110</td>\n      <td>2.013192</td>\n      <td>221.451137</td>\n      <td>also</td>\n      <td>124</td>\n      <td>1.328749</td>\n      <td>164.764861</td>\n      <td>good</td>\n      <td>108</td>\n      <td>1.427116</td>\n      <td>154.128566</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>true</td>\n      <td>109</td>\n      <td>1.808709</td>\n      <td>197.149284</td>\n      <td>graphics</td>\n      <td>234</td>\n      <td>0.940555</td>\n      <td>220.089953</td>\n      <td>spacecraft</td>\n      <td>81</td>\n      <td>1.995921</td>\n      <td>161.669566</td>\n      <td>law</td>\n      <td>84</td>\n      <td>1.832581</td>\n      <td>153.936843</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>must</td>\n      <td>157</td>\n      <td>1.252763</td>\n      <td>196.683786</td>\n      <td>points</td>\n      <td>87</td>\n      <td>2.457878</td>\n      <td>213.835384</td>\n      <td>first</td>\n      <td>110</td>\n      <td>1.454790</td>\n      <td>160.026856</td>\n      <td>christians</td>\n      <td>83</td>\n      <td>1.714798</td>\n      <td>142.328270</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>many</td>\n      <td>164</td>\n      <td>1.141537</td>\n      <td>187.212123</td>\n      <td>processing</td>\n      <td>69</td>\n      <td>2.968704</td>\n      <td>204.840548</td>\n      <td>orbit</td>\n      <td>118</td>\n      <td>1.355417</td>\n      <td>159.939220</td>\n      <td>life</td>\n      <td>85</td>\n      <td>1.634756</td>\n      <td>138.954236</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>islamic</td>\n      <td>102</td>\n      <td>1.834685</td>\n      <td>187.137820</td>\n      <td>display</td>\n      <td>90</td>\n      <td>2.242767</td>\n      <td>201.848994</td>\n      <td>lunar</td>\n      <td>70</td>\n      <td>2.258285</td>\n      <td>158.079938</td>\n      <td>said</td>\n      <td>97</td>\n      <td>1.427116</td>\n      <td>138.430286</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>morality</td>\n      <td>96</td>\n      <td>1.916923</td>\n      <td>184.024571</td>\n      <td>package</td>\n      <td>96</td>\n      <td>2.093235</td>\n      <td>200.950547</td>\n      <td>satellites</td>\n      <td>50</td>\n      <td>3.094533</td>\n      <td>154.726643</td>\n      <td>matthew</td>\n      <td>57</td>\n      <td>2.407946</td>\n      <td>137.252900</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>believe</td>\n      <td>145</td>\n      <td>1.252763</td>\n      <td>181.650630</td>\n      <td>color</td>\n      <td>106</td>\n      <td>1.764731</td>\n      <td>187.061464</td>\n      <td>market</td>\n      <td>50</td>\n      <td>2.951432</td>\n      <td>147.571601</td>\n      <td>values</td>\n      <td>48</td>\n      <td>2.733368</td>\n      <td>131.201664</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>dont</td>\n      <td>233</td>\n      <td>0.771790</td>\n      <td>179.827142</td>\n      <td>system</td>\n      <td>89</td>\n      <td>2.093235</td>\n      <td>186.297903</td>\n      <td>system</td>\n      <td>85</td>\n      <td>1.689190</td>\n      <td>143.581176</td>\n      <td>hanging</td>\n      <td>31</td>\n      <td>4.199705</td>\n      <td>130.190857</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>religious</td>\n      <td>102</td>\n      <td>1.711071</td>\n      <td>174.529197</td>\n      <td>3d</td>\n      <td>117</td>\n      <td>1.582409</td>\n      <td>185.141881</td>\n      <td>mission</td>\n      <td>69</td>\n      <td>2.075963</td>\n      <td>143.241466</td>\n      <td>many</td>\n      <td>94</td>\n      <td>1.347074</td>\n      <td>126.624923</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>religion</td>\n      <td>115</td>\n      <td>1.501979</td>\n      <td>172.727557</td>\n      <td>send</td>\n      <td>75</td>\n      <td>2.457878</td>\n      <td>184.340848</td>\n      <td>said</td>\n      <td>70</td>\n      <td>2.021896</td>\n      <td>141.532724</td>\n      <td>also</td>\n      <td>98</td>\n      <td>1.290984</td>\n      <td>126.516450</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 65
    }
   ],
   "source": [
    "df2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python361064bitvenvamlcondaa2885660b66d41daa25a25cbab9819c5",
   "display_name": "Python 3.6.10 64-bit ('venvaml': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}