# Azure Pipeline Definition for ML CD
# @TODO model registry event to trigger this pipeline

# Trigger on changes in the Model CI pipeline                 
resources:
  pipelines:
  - pipeline: modelci   # Name of the pipeline resource
    source: "ML Model CI" # Name of the triggering pipeline
    trigger: 
      branches:
      - master

# Some steps in this pipeline use upstream generated model outputs
# for testing and deployment. We pass these in as pipeline parameters.
parameters:
- name: modelName
  type: string
  default: net.onnx  # tmp
- name: modelVersion
  type: number
  default: 3 # tmp

stages:
- stage: ModelValidation
  displayName: 'Model Validation'
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts

    - script: |
        python code/build-and-release/scripts/download_model.py \
        --name ${{ parameters.modelName }} \
        --version ${{ parameters.modelVersion }}
      displayName: Download Model Outputs
    
    # Load Scoring Environment
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      displayName: Add Conda to PATH

    - script: |
        conda env create -n scoringenv --file code/environments/scoring/conda_dependencies.yml
      displayName: Load Scoring Environment

    # Model Validation Tests
    - script: |
        source activate scoringenv
        pytest --junitxml=test_report_modelvalidation.xml
      workingDirectory: code/tests/model_validation
      displayName: 'Model Validation Tests'

    - task: PublishTestResults@2
      displayName: 'Publish Test Results'
      inputs:
        testResultsFiles: 'code/tests/model_validation/test_report_modelvalidation.xml'
        testRunTitle: '$(projectname): Model Validation Test Results'
        failTaskOnFailedTests: true # unifies failure across different types of tests
      condition: succeededOrFailed()
      
- stage: IntegrationTestScoringApp
  displayName: 'Integration Tests Scoring App'
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts
    
    # Load Scoring Environment
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      displayName: Add Conda to PATH

    - script: |
        conda env create -n scoringenv --file code/environments/scoring/conda_dependencies.yml
      displayName: Load Scoring Environment

- stage: DeployScoringApp
  displayName: 'Deploy the Scoring App'
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts

- stage: SystemIntegrationTests
  displayName: 'System Integration Tests'
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts

- stage: LoadTesting
  displayName: 'Load Test Scoring App'
  # Deploy scoring app and system integrate
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts

- stage: DeployPROD
  displayName: 'Deploy PROD'
  jobs:
  - job: Validate_Model
    pool:
      vmImage: 'ubuntu-16.04'

    steps:
    - download: current
      artifact: ModelCIBuildArtifacts

# - stage: ReleaseDEV
#   displayName: 'Release to DEV'
#   jobs:
#   - job: Deploy_ML_Pipeline
#     displayName: Deploy ML Pipeline
#     pool:
#       vmImage: 'ubuntu-16.04'
#     variables:
#     - name: resourceGroupName
#       value: aml-mlops-workshop-dev
#     - name: resourceGroupLocation
#       value: westeurope
#     - name: amlWorkspaceName
#       value: aml-mlops-workspace-dev

#     steps:
#     - download: current
#       artifact: ModelCIBuildArtifacts
  
#     - task: AzureCLI@2
#       displayName: Generate AML Workspace Config File
#       inputs:
#         azureSubscription: "my-service-connection"
#         scriptType: bash
#         scriptLocation: inlineScript
#         inlineScript: |
#           az extension add -n azure-cli-ml
#           az ml folder attach -w $(amlWorkspaceName) -g $(resourceGroupName)
  
#     # @TODO Integration tests on scorer app
#     # @TODO Model validation tests
#     # @TODO Integration tests

#     - task: AzureCLI@2
#       displayName: Publish ML Pipeline
#       inputs:
#         azureSubscription: "my-service-connection"
#         scriptType: bash
#         scriptLocation: inlineScript
#         inlineScript: |
#           python code/build-and-release/scripts/publish_pipeline_from_yml.py --definition $(aml_ci_pipeline_definition)

#     # @TODO+optional Run published pipeline
#     # - task: MLPublishedPipelineRestAPITask@0
#     #   inputs:
#     #     PipelineParameters: '"key1": "value2"'
#     #   displayName: Run Published ML Pipeline